extended_prediction_power <- predict(power_model, newdata = newdata)
# Predict using the LOESS model over the newdata for consistency in plot
loess_predictions <- predict(loess_model, newdata = newdata)
#hybrid model development
#pick a threshold value from the plot above where the power model should take over
# These values are not final
threshold_level <- c("BYS" = 1.06,
"CLD" = 1.97,
"MEW_DS" = 1,
"MEW_US" = 1.06,
"MEW" = 1.86,
"MLL" = 0.77,
"PRY" = 0.7,
"WHT" = 1.06,
"UDC" = 1.09,
"LDM" = 0
)
####
hybrid_prediction <- function(level) {
# If the level is exactly 0, return 0 as the predicted discharge
#if(level == 0) return(0)
# Use the LOESS model for levels below or equal to the threshold
if (level <= threshold_level[site]) {
loess_pred <- predict(loess_model, newdata = data.frame(level_corrected_ft = level))
# If the LOESS model prediction is not NA, return it
if (!is.na(loess_pred)) {
return(loess_pred)
}
}
# Use the power model for levels above the threshold or if the LOESS model returned NA
power_pred <- predict(power_model, newdata = data.frame(level_corrected_ft = level))
if (!is.na(power_pred)) {
return(power_pred)
}
# If both models return NA (which shouldn't happen with valid data), handle the case explicitly
# You may choose to return NA or an interpolated value between the two models
# This requires additional handling depending on your knowledge of the data
return(NA)  # or consider another method of handling unexpected NA values
}
# Apply the updated hybrid model to a sequence of levels
levels_seq <- seq(0, extension_value, length.out = 100) # Starting from 0
hybrid_predictions <- sapply(levels_seq, hybrid_prediction)
############# Fit Analysis ##########################
# Percent error of manually measured discharge and predicted discharge, and Root Mean Square Error #
# Calculated the predicted discharge at the levels of all the manual measurements
if(hybrid_data == TRUE){
predicted_discharge <- sapply(combined_data$level_corrected_ft, hybrid_prediction)
}else{
predicted_discharge <- predict(power_model, combined_data$level_corrected_ft)
}
# Get all of the manual measurment data in the right format
comparison_df <- combined_data[, c("date.time", "staffplate.cm","flowmeter","level_corrected_ft")]
comparison_df$measured_q.cfs <- combined_data$q.cfs
comparison_df$predicted_q.cfs <- predicted_discharge
# Calculate percent error of each measurement, add as a column
comparison_df$percent_error <- abs(comparison_df$measured_q.cfs - comparison_df$predicted_q.cfs) / abs(comparison_df$predicted_q.cfs) * 100
#print(comparison_df)
# Calculate the root mean square error of the fit
rmse <- sqrt(mean((comparison_df$measured_q.cfs - comparison_df$predicted_q.cfs)^2))
#print(rmse)
# Calculate average percent error across all manual measurements
avg_percent_error <- mean(comparison_df$percent_error)
if(write_rating_stats == TRUE){
# Write the comparison_df with measured vs predicted percent error and RMSE
stats_file_path <- paste0(Streamflow_Archive_path,"Rating_Curve_Stats/",site,"_stats.csv")
write.csv(comparison_df,file = stats_file_path, row.names = FALSE)
cat(sprintf("Avg Percent Error:,%.4f\n", avg_percent_error), file = stats_file_path, append = TRUE) # Add the average percent error to the end of the csv
cat(sprintf("RMSE:,%.4f\n", rmse), file = stats_file_path, append = TRUE) # Add the RMSE to the end of the csv
cat("Rating Curve fit stats have been written to", stats_file_path, "\n")
}
#### Prepare to plot rating curve with WY measurements called out########
# Add a new column to differentiate measurements by date
combined_data <- combined_data %>%
mutate(
measurement_type = case_when(
date.time >= as.Date("2024-10-01") ~ "WY 25 Field Measurements",
date.time >= as.Date("2023-10-01") ~ "WY 24 Field Measurements",
date.time >= as.Date("2022-10-01") ~ "WY 23 Field Measurements",
date.time >= as.Date("2021-10-01") ~ "WY 22 Field Measurements",
date.time >= as.Date("2020-10-01") ~ "WY 21 Field Measurements",
date.time >= as.Date("2019-10-01") ~ "WY 20 Field Measurements",
date.time >= as.Date("2018-10-01") ~ "WY 19 Field Measurements",
date.time >= as.Date("2017-10-01") ~ "WY 18 Field Measurements",
TRUE ~ "WY 17 Field Measurements",
)
)
# Add the rest of your plotly plot elements here
#Annotate the plot with p-value and R-squared for the power model
if(use_stats == TRUE && use_intercept == TRUE){
annotation_text_WY <- paste("Power Model",
#"<br>p-value: ",
#round(p_value, 4),
#"<br>R-squared: ",
#round(r_squared, 4),
"<br> a: ",
round(coef(power_model)[1],4),
"<br> b: ",
round(coef(power_model)[2],4),
"<br> c: ",
round(coef(power_model)[3],4),
"<br> RMSE: ",
round(rmse,4))
}else if(use_stats == TRUE && use_intercept == FALSE){
annotation_text_WY <- paste("Power Model",
#"<br>p-value: ",
#round(p_value, 4),
#"<br>R-squared: ",
#round(r_squared, 4),
"<br> a: ",
round(coef(power_model)[1],4),
"<br> b: ",
round(coef(power_model)[2],4),
"<br> RMSE: ",
round(rmse,4))
}else{
annotation_text_WY = ""
}
library(viridisLite)
unique_measurements <- length(unique(combined_data$measurement_type))
turbo_colors <- turbo(unique_measurements)
# Add the rest of your plotly plot elements here (as per your original code)
WY_Rating <- plot_ly() %>%
add_lines(data = newdata, x = ~level_corrected_ft, y = ~extended_prediction_power,
line = list(color = 'rgba(97, 205, 187, 0.8)', width = 3, dash = 'dot'), name = 'Power Model')
if (use_loess == TRUE){
WY_Rating <- WY_Rating %>%
add_lines(data = newdata, x = ~level_corrected_ft, y = ~loess_predictions,
line = list(color = 'rgba(241, 90, 96, 0.8)', width = 3, dash = 'dash'), name = 'LOESS Model')
}
if (hybrid_data == TRUE){
WY_Rating <- WY_Rating %>%
add_lines(data = combined_data, x = ~levels_seq, y = ~hybrid_predictions,
line = list(color = 'rgba(128, 133, 233, 0.8)', width = 3, dash = 'dot'), name = 'Hybrid Model')
}
WY_Rating <- WY_Rating %>%
add_markers(data = combined_data, x = ~level_corrected_ft, y = ~q.cfs,
color= ~measurement_type,
marker = list(size = 12, width = 2),
colors = turbo_colors,
text = ~paste("Level: ", level_corrected_ft, " ft<br>Discharge: ", q.cfs, " cfs<br>Date: ", date.time),
hoverinfo = "text",
name = ~measurement_type) %>%
layout(title = paste(site, "Rating Curve"),
xaxis = list(title = "Stage (ft)", showgrid = TRUE, gridcolor = '#e2e2e2',range = list(0, max_level+0.5)),
yaxis = list(title = "Discharge (cfs)", showgrid = TRUE, gridcolor = '#e2e2e2',range = list(0, max_discharge_measurement+100)),
legend = list(x = 0.75, y = 1, xanchor = 'left', yanchor = 'top', bgcolor = 'rgba(255, 255, 255, 0.8)', bordercolor = 'rgba(200, 200, 200, 0.5)'),
plot_bgcolor = 'rgba(240, 240, 240, 0.95)',
paper_bgcolor = 'rgba(255, 255, 255, 0.95)',
annotations = list(
list(
x = 0.05,
y = 0.95,
text = annotation_text_WY,
xref = "paper",
yref = "paper",
showarrow = FALSE,
font = list(
size = 12,
color = "black"
),
align = "left"
)
),
margin = list(
l = 70,  # left margin
r = 0,  # right margin
b = 70,  # bottom margin
t = 50, # top margin
pad = 0  # optional padding between plot and margin
))
print(WY_Rating)
rm(list=ls())
# Load necessary libraries
library(tidyr)
library(lubridate)
library(readr)
library(plotly)
# library(minpack.lm)  # May not be needed if we are not using Levenberg-Marquardt algorithms
library(anytime)
#library(MASS)  # May not be needed in this script as it is
library(dplyr)
library(zoo)
#Start here
####### select the site name #####
site="LDM" #NOTE: Update site name as required
####### set True if you want the hybrid data plotted ######
use_stats = FALSE
use_intercept = FALSE
use_loess = FALSE
hybrid_data = FALSE
filter_outliers = FALSE
write_rating_stats = FALSE # set True if you want to output a csv with model vs observation stats
write_rating_tables = FALSE # set True if you want to output a csv with the rating table
######  select path to server #####
#Streamflow_Archive_path <- "//Skyriver.ucsd.edu/CW3E_data/CW3E_Streamflow_Archive/" # Update path as required
# I downloaded all the necessary files to a local directory on my computer called 'test_Streamflow_Archive'"
Streamflow_Archive_path <- "C:/Users/cw3e/Documents/streams/test_Streamflow_Archive/"
#Streamflow_Archive_path <- "/Users/cloudy-guest/remote/data/CW3E_data/CW3E_Streamflow_Archive/" #path on Sarah O's computer
######### Read in the data #############
# Read continuous level data
#continuous_data <- read_csv(paste(Streamflow_Archive_path, site, "/Processed/ALL.", site, ".Level.Discharge.csv", sep=""))
# For now, the full spreadsheet of data will be named 'site_MasterTable_Processed.csv'.
# They will no longer be named 'ALL.site.Level.Discharge.csv"
continuous_data <- read_csv(paste(Streamflow_Archive_path, site, "/Processed/", site, "_MasterTable_Processed.csv", sep=""))
#for MEW on Sarah Ogle's computer (this is the file with MEW DS and US combined by predicting what MEW DS would have been if measured by the US sensor)
#continuous_data <- read_csv(paste0("/Users/cloudy-guest/Documents/GitHub/Streamflow-Processing/CW3E_Streamflow_Processing/CW3E_Streamflow_Processing/Manual_Level_Corrections/Outputs/", site, "/MEW_DS_predicted_US_observed_level.csv")) #for MEW
#round timestamp to the nearest minute
continuous_data$timestamp_UTC <- floor_date(continuous_data$timestamp_UTC, unit = "minute")
#set the -9999s to NA
continuous_data$level_corrected_ft[continuous_data$level_corrected_ft <= -9999] <- NA
continuous_data$level_corrected_m[continuous_data$level_corrected_m <= -9999.99] <- NA
#continuous_data$level_corrected_cm[continuous_data$level_corrected_cm == -9999.99] <- NA
# Read in manual discharge measurements
manual_discharge_data <- read_csv(paste(Streamflow_Archive_path, site, "/Manual_Discharge/", site, "_manual_q_final.csv", sep=""))
manual_discharge_data$date.time <- anytime(manual_discharge_data$date.time)
manual_discharge_data$date.time <- force_tz(manual_discharge_data$date.time, tzone = "UTC")
manual_discharge_data$date.time <- as.POSIXct(round_date(manual_discharge_data$date.time, unit = "15 minutes"))
manual_discharge_data <- manual_discharge_data %>%
mutate(staffplate.feet = if_else(is.na(staffplate.cm), NA_real_, staffplate.cm * 0.0328084))
#Set any negative flow measurements to zero.  This is only if we think there's a sensor error.  Backflow is legit and should be considered part of the rating curve if we think it's actual backflow
#manual_discharge_data  <- manual_discharge_data  %>%
# filter(q.cfs >= 0)
#########################################################################
###########  Rating Curve Development ##############################
#################################################################
# Remove outliers from manual discharge measurements using IQR (only if we think there are outliers)
IQR <- IQR(manual_discharge_data$q.cfs, na.rm = TRUE)
Q1 <- quantile(manual_discharge_data$q.cfs, 0.25, na.rm = TRUE)
Q3 <- quantile(manual_discharge_data$q.cfs, 0.75, na.rm = TRUE)
lower_bound <- Q1 - 1.5 * IQR
upper_bound <- Q3 + 1.5 * IQR
if (filter_outliers == TRUE) {
manual_discharge_data <- manual_discharge_data %>%
filter(q.cfs >= lower_bound & q.cfs <= upper_bound)
}
#account for channel change at MLL and outlier value in January 2018
if (site == "MLL") {
manual_discharge_data <- subset(manual_discharge_data, manual_discharge_data$date.time < "2023-03-19")
manual_discharge_data <- subset(manual_discharge_data, manual_discharge_data$staffplate.cm != 89)
}
if (site == "WHT") {
manual_discharge_data <- subset(manual_discharge_data, manual_discharge_data$q.cfs != 4.81)
}
if (site == "UDC") {
#manual_discharge_data <- subset(manual_discharge_data, manual_discharge_data$q.cfs != 10.57) # Sarah B's first solo manual discharge measurement
#manual_discharge_data <- subset(manual_discharge_data, manual_discharge_data$q.cfs != -0.001) # Didn't seem right so did a second measurement that looked better that day
}
if (site == "LDM"){
manual_discharge_data <- subset(manual_discharge_data, manual_discharge_data$q.cfs != 240.79)
}
# Combine continuous timeseries data with manual discharge measurements
continuous_data$timestamp_UTC <- as.POSIXct(round_date(continuous_data$timestamp_UTC, unit = "15 minutes"))
# Fill in level NAs with closest level within an hour, in case manual measurement was taken during solinst download.
# Set a 1-hour window
time_window <- 60 * 60 # 1 hour in seconds
#TODO: I never actually confirmed that the values it replaces the Nans with look correct, though it seems to be working
# Fill NAs in level_corrected_ft with the nearest value within the 1-hour time window
continuous_data_filled <- continuous_data %>%
mutate(
level_corrected_ft_filled = zoo::na.approx(level_corrected_ft, timestamp_UTC, maxgap = time_window, na.rm = FALSE)
)
combined_data <- left_join(manual_discharge_data, continuous_data_filled, by = c("date.time" = "timestamp_UTC"))
combined_data <- combined_data %>%
filter(!is.na(level_corrected_ft_filled))
combined_data$level_corrected_ft <- combined_data$level_corrected_ft_filled
# Fit a LOESS model
loess_model <- loess(q.cfs ~ level_corrected_ft, data = combined_data, span = 0.9, degree = 2, model = TRUE)
# Fit a power function model to the data for extrapolation
max_level <- max(continuous_data$level_corrected_ft, na.rm = TRUE)
extension_value <- 1.5 * max_level #this likely should be slightly above bankful level
#levels_seq <- seq(min(continuous_data$level_corrected_ft, na.rm = TRUE), extension_value, length.out = 100)
levels_seq <- seq(0.001, extension_value, length.out = 100)
newdata <- data.frame(level_corrected_ft = levels_seq)
max_discharge_measurement = max(manual_discharge_data$q.cfs)
# Log-transform the data
log_data <- transform(combined_data, log_q.cfs = log(q.cfs), log_level = log(level_corrected_ft))
# Fit a linear model on the log-transformed data
linear_mod <- lm(log_q.cfs ~ log_level, data = log_data)
#Sarah O: LIKELY CAN DELETE BELOW 4 LINES SINCE I DONT THINK WE USE THE LINEAR MODEL (so don't need its statistics)
# Calculate p-value and R-squared for the linear model
summary_linear_mod <- summary(linear_mod)
#p_value <- summary_linear_mod$coefficients[2, 4] #don't think we end up using p-value or r-squared for linear model...
#r_squared <- summary_linear_mod$r.squared
# Get starting values from the linear model
start_a <- exp(coef(linear_mod)[1])
start_b <- coef(linear_mod)[2]
start_intercept = exp(coef(linear_mod)[1]) #this is the intercept of the linear model
#set constraints for maximum b value
b_max = 2.67
if (site == "PRY") {
b_max = 0.85
}
if (site == "WHT") {
b_max = 3.69
}
if (site == "MEW") {
b_max = 3.5
}
# Fit the power model using the starting values derived from the linear model (set limits for b based on literature (https://onlinelibrary.wiley.com/doi/full/10.1002/env.2711: says b is usually 1-2.67)
# adjust to b = 0.85 for PRY to make PRY converge (PRY likely isn't quite ratable)
# intercepts in the power model allow the discharge to be something other then 0 at stage = 0
if(use_intercept == TRUE){
power_model <- nls(q.cfs ~ a * level_corrected_ft^b + intercept,
data = combined_data,
start = list(a = start_a, b = start_b, intercept = start_intercept),
algorithm = "port",
lower = (c(a= 0, b = 0, intercept = -100)),
upper = c(a = 50, b = 50, intercept = 100)
)
}else{
power_model <- nls(q.cfs ~ a * level_corrected_ft^b,
data = combined_data,
start = list(a = start_a, b = start_b),
algorithm = "port",
lower = (c(a= 0, b = 0)),
upper = c(a = 50, b = 50)
)
}
summary_power_model <- summary(power_model)
#extend the prediction
extended_prediction_power <- predict(power_model, newdata = newdata)
# Predict using the LOESS model over the newdata for consistency in plot
loess_predictions <- predict(loess_model, newdata = newdata)
#hybrid model development
#pick a threshold value from the plot above where the power model should take over
# These values are not final
threshold_level <- c("BYS" = 1.06,
"CLD" = 1.97,
"MEW_DS" = 1,
"MEW_US" = 1.06,
"MEW" = 1.86,
"MLL" = 0.77,
"PRY" = 0.7,
"WHT" = 1.06,
"UDC" = 1.09,
"LDM" = 0
)
####
hybrid_prediction <- function(level) {
# If the level is exactly 0, return 0 as the predicted discharge
#if(level == 0) return(0)
# Use the LOESS model for levels below or equal to the threshold
if (level <= threshold_level[site]) {
loess_pred <- predict(loess_model, newdata = data.frame(level_corrected_ft = level))
# If the LOESS model prediction is not NA, return it
if (!is.na(loess_pred)) {
return(loess_pred)
}
}
# Use the power model for levels above the threshold or if the LOESS model returned NA
power_pred <- predict(power_model, newdata = data.frame(level_corrected_ft = level))
if (!is.na(power_pred)) {
return(power_pred)
}
# If both models return NA (which shouldn't happen with valid data), handle the case explicitly
# You may choose to return NA or an interpolated value between the two models
# This requires additional handling depending on your knowledge of the data
return(NA)  # or consider another method of handling unexpected NA values
}
# Apply the updated hybrid model to a sequence of levels
levels_seq <- seq(0, extension_value, length.out = 100) # Starting from 0
hybrid_predictions <- sapply(levels_seq, hybrid_prediction)
############# Fit Analysis ##########################
# Percent error of manually measured discharge and predicted discharge, and Root Mean Square Error #
# Calculated the predicted discharge at the levels of all the manual measurements
if(hybrid_data == TRUE){
predicted_discharge <- sapply(combined_data$level_corrected_ft, hybrid_prediction)
}else{
predicted_discharge <- predict(power_model, combined_data$level_corrected_ft)
}
# Get all of the manual measurment data in the right format
comparison_df <- combined_data[, c("date.time", "staffplate.cm","flowmeter","level_corrected_ft")]
comparison_df$measured_q.cfs <- combined_data$q.cfs
comparison_df$predicted_q.cfs <- predicted_discharge
# Calculate percent error of each measurement, add as a column
comparison_df$percent_error <- abs(comparison_df$measured_q.cfs - comparison_df$predicted_q.cfs) / abs(comparison_df$predicted_q.cfs) * 100
#print(comparison_df)
# Calculate the root mean square error of the fit
rmse <- sqrt(mean((comparison_df$measured_q.cfs - comparison_df$predicted_q.cfs)^2))
#print(rmse)
# Calculate average percent error across all manual measurements
avg_percent_error <- mean(comparison_df$percent_error)
if(write_rating_stats == TRUE){
# Write the comparison_df with measured vs predicted percent error and RMSE
stats_file_path <- paste0(Streamflow_Archive_path,"Rating_Curve_Stats/",site,"_stats.csv")
write.csv(comparison_df,file = stats_file_path, row.names = FALSE)
cat(sprintf("Avg Percent Error:,%.4f\n", avg_percent_error), file = stats_file_path, append = TRUE) # Add the average percent error to the end of the csv
cat(sprintf("RMSE:,%.4f\n", rmse), file = stats_file_path, append = TRUE) # Add the RMSE to the end of the csv
cat("Rating Curve fit stats have been written to", stats_file_path, "\n")
}
#### Prepare to plot rating curve with WY measurements called out########
# Add a new column to differentiate measurements by date
combined_data <- combined_data %>%
mutate(
measurement_type = case_when(
date.time >= as.Date("2024-10-01") ~ "WY 25 Field Measurements",
date.time >= as.Date("2023-10-01") ~ "WY 24 Field Measurements",
date.time >= as.Date("2022-10-01") ~ "WY 23 Field Measurements",
date.time >= as.Date("2021-10-01") ~ "WY 22 Field Measurements",
date.time >= as.Date("2020-10-01") ~ "WY 21 Field Measurements",
date.time >= as.Date("2019-10-01") ~ "WY 20 Field Measurements",
date.time >= as.Date("2018-10-01") ~ "WY 19 Field Measurements",
date.time >= as.Date("2017-10-01") ~ "WY 18 Field Measurements",
TRUE ~ "WY 17 Field Measurements",
)
)
# Add the rest of your plotly plot elements here
#Annotate the plot with p-value and R-squared for the power model
if(use_stats == TRUE && use_intercept == TRUE){
annotation_text_WY <- paste("Power Model",
#"<br>p-value: ",
#round(p_value, 4),
#"<br>R-squared: ",
#round(r_squared, 4),
"<br> a: ",
round(coef(power_model)[1],4),
"<br> b: ",
round(coef(power_model)[2],4),
"<br> c: ",
round(coef(power_model)[3],4),
"<br> RMSE: ",
round(rmse,4))
}else if(use_stats == TRUE && use_intercept == FALSE){
annotation_text_WY <- paste("Power Model",
#"<br>p-value: ",
#round(p_value, 4),
#"<br>R-squared: ",
#round(r_squared, 4),
"<br> a: ",
round(coef(power_model)[1],4),
"<br> b: ",
round(coef(power_model)[2],4),
"<br> RMSE: ",
round(rmse,4))
}else{
annotation_text_WY = ""
}
library(viridisLite)
unique_measurements <- length(unique(combined_data$measurement_type))
turbo_colors <- turbo(unique_measurements)
# Add the rest of your plotly plot elements here (as per your original code)
WY_Rating <- plot_ly() %>%
add_lines(data = newdata, x = ~level_corrected_ft, y = ~extended_prediction_power,
line = list(color = 'rgba(97, 205, 187, 0.8)', width = 3, dash = 'dot'), name = 'Power Model')
if (use_loess == TRUE){
WY_Rating <- WY_Rating %>%
add_lines(data = newdata, x = ~level_corrected_ft, y = ~loess_predictions,
line = list(color = 'rgba(241, 90, 96, 0.8)', width = 3, dash = 'dash'), name = 'LOESS Model')
}
if (hybrid_data == TRUE){
WY_Rating <- WY_Rating %>%
add_lines(data = combined_data, x = ~levels_seq, y = ~hybrid_predictions,
line = list(color = 'rgba(128, 133, 233, 0.8)', width = 3, dash = 'dot'), name = 'Hybrid Model')
}
WY_Rating <- WY_Rating %>%
add_markers(data = combined_data, x = ~level_corrected_ft, y = ~q.cfs,
color= ~measurement_type,
marker = list(size = 12, width = 2),
colors = turbo_colors,
text = ~paste("Level: ", level_corrected_ft, " ft<br>Discharge: ", q.cfs, " cfs<br>Date: ", date.time),
hoverinfo = "text",
name = ~measurement_type) %>%
layout(title = paste(site, "Rating Curve"),
xaxis = list(title = "Stage (ft)", showgrid = TRUE, gridcolor = '#e2e2e2',range = list(0, max_level+0.5)),
yaxis = list(title = "Discharge (cfs)", showgrid = TRUE, gridcolor = '#e2e2e2',range = list(0, max_discharge_measurement+100)),
legend = list(x = 0.75, y = 1, xanchor = 'left', yanchor = 'top', bgcolor = 'rgba(255, 255, 255, 0.8)', bordercolor = 'rgba(200, 200, 200, 0.5)'),
plot_bgcolor = 'rgba(240, 240, 240, 0.95)',
paper_bgcolor = 'rgba(255, 255, 255, 0.95)',
annotations = list(
list(
x = 0.05,
y = 0.95,
text = annotation_text_WY,
xref = "paper",
yref = "paper",
showarrow = FALSE,
font = list(
size = 12,
color = "black"
),
align = "left"
)
),
margin = list(
l = 70,  # left margin
r = 0,  # right margin
b = 70,  # bottom margin
t = 50, # top margin
pad = 0  # optional padding between plot and margin
))
print(WY_Rating)
shiny::runApp('GitHub/StreamflowDashboard')
for (stream_site in stream_sites) {
ratingcurve_data <- read.csv(paste(config$ratingcurve_data_path, paste("UDC_Rating_Curve.csv", sep = ""), sep = ""), header = TRUE)
assign(paste(stream_site, "_RC", sep = ""), ratingcurve_data)
}
stream_sites = ["UDC"]
stream_sites = }"UDC"}
stream_sites = {"UDC"}
for (stream_site in stream_sites) {
ratingcurve_data <- read.csv(paste(config$ratingcurve_data_path, paste("UDC_Rating_Curve.csv", sep = ""), sep = ""), header = TRUE)
assign(paste(stream_site, "_RC", sep = ""), ratingcurve_data)
}
ratingcurvepath = "CW3E_Streamflow_Archive/UDC/Processed/"
ratingcurve_data <- read.csv(paste(config$ratingcurve_data_path, paste("UDC_Rating_Curve.csv", sep = ""), sep = ""), header = TRUE)
ratingcurve_data <- read.csv(paste(ratingcurvepath, paste("UDC_Rating_Curve.csv", sep = ""), sep = ""), header = TRUE)
ratingcurvepath = "C:/Users/cw3e/Documents/GitHub/StreamflowDashboard/data/CW3E_Streamflow_Archive/UDC/Processed/"
ratingcurve_data <- read.csv(paste(ratingcurvepath, paste("UDC_Rating_Curve.csv", sep = ""), sep = ""), header = TRUE)
print(ratingcurve_data)
ratingcurve_data <- ratingcurve_data[-c(1,2),]
print(ratingcurve_data)
runApp('GitHub/StreamflowDashboard')
